{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diving Deep into the Twitter API\n",
    "\n",
    "### Twitter API and Authentication\n",
    "\n",
    "- Stream data from Twitter API\n",
    "- Filter incoming tweets for keywords\n",
    "- About API authentication and OAuth Principles\n",
    "- Basics of the package Tweepy, many Python users use to interact with Twitter\n",
    "\n",
    "Twitter API requires you have an account\n",
    "1. Create Twitter Account\n",
    "2. Login to apps.twitter.com, 'Create new app'\n",
    "3. agree to T&C\n",
    "4. Retrieve Authentication credentials that will allow you to access the Twitter API.  Go to 'Keys and Access Tokens' tab and copy\n",
    "    - API Key\n",
    "    - API Secret\n",
    "    - Access Token\n",
    "    - Access Token Secret\n",
    "\n",
    "Twitter has a number of APIs:\n",
    "1. REST API - provide programmatic access to read/write Twitter data.  Author a new Tweet, read author profile and follower data, and more.  The REST API identifies Twitter applications and users using OAuth; responses are available in JSON.  \n",
    "    - REST is short for Representational State Transfer\n",
    "    - Twitter's REST allows you to Read and Write Twitter data\n",
    "    - Good for conducting singular searches, read user profile information, or post Tweets   \n",
    "2. If your intention is to monitor or process Tweets in real-time, consider using the Streaming API\n",
    "    - The Streaming APIs give develpers low latency access to Twitter's global stream of Tweet data.  A proper implmentation of a streaming client will be pushed messages indicating Tweets and other events have occurred, without any of the overhead associated with pollin a REST endpoint.  \n",
    "    - Several Streaming Endpoints\n",
    "    - Public Streams - Streams of the public data flowing through Twitter suitable for following specific users or topics, and data mining\n",
    "    - User Streams - single-user streams, containing roughtly all of the data corresponding with a single user's view of Twitter\n",
    "    - Site Streams - The multi-user version of user streams.  Site streams are intended for servers which must connect to Twitter on behalf of many users.\n",
    "\n",
    "    \n",
    "\n",
    "#### We will be using the Public Stream:\n",
    "- GET statuses/sample API\n",
    "    -Returns a small random sample of all public statuses.  The Tweets returned by the default access level are the same, so if two different clients connect to this endpoint, they will see the same Tweets\n",
    "\n",
    "- Resource URL\n",
    "    - https:/stream.twitter.com/1.1/statuses/sample.json\n",
    "\n",
    "- Firehose API - GET stuses/firehose\n",
    "    - This endpoint requires special permission to acccess.\n",
    "    - Returns all public statuses.  Few applications require this level of access.  Creative use of a combination of other resources and various access levels can satisfy nearly every application use case.\n",
    "    - costs Money\n",
    "    \n",
    "#### Tweets are returned as JSONs\n",
    "- https://dev.twitter.com/overview/api/tweets\n",
    "- Field guide, get tweet text, language, time of tweet, among many other fields\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweepy Package\n",
    "\n",
    "Recommended for first time Twitter APIs users.  Has a nice balance of usability and capability\n",
    "\n",
    "Has an OAuth handler, which takes care of all of the nasty stuff for you:  all you need to do is pass the API key and Secret to the handler and then to pass the access credentials using the set_access_token method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b3e87fe021bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccess_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "\n",
    "import tweepy, json\n",
    "\n",
    "access_token = \"...\"\n",
    "access_token_secret = \"...\"\n",
    "consumer_key = \"...\"\n",
    "consumer_secret = \"...\"\n",
    "\n",
    "# pass the API Key and Secret to the handler\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# pass the access credentials using the set_access_token method\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, you'll need to define the Twitter Stream Listener Class\n",
    "\n",
    "datacamp will define this for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You need to define your Twitter Stream User Class\n",
    "# Tweepy: define stream listener class\n",
    "\n",
    "import tweepy, json\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets=0\n",
    "        self.file = open(\"tweets.txt\", \"w\") #create tweets.txt\n",
    "        \n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write(json.dumps(tweet) + '\\n') #writes to file\n",
    "        tweet_list.append(status)\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 100:  # closes after 100 tweets\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()  # Listener closes the file, and stops listening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the Stream Listener Class, you need to authenticate it.  You can then stream tweets that contain keywords by applying filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b077e4a403ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create Streaming object and authenticate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyStreamListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This line filters Twitter Streams to capture data by Keywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auth' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Streaming object and authenticate\n",
    "l = MyStreamListener()\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "# This line filters Twitter Streams to capture data by Keywords\n",
    "stream.filter(track=['apples', 'oranges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Authentication\n",
    "\n",
    "The package tweepy is great at handling all the Twitter API OAuth Authentication details for you. All you need to do is pass it your authentication credentials. In this interactive exercise, we have created some mock authentication credentials (if you wanted to replicate this at home, you would need to create a Twitter App as Hugo detailed in the video). Your task is to pass these credentials to tweepy's OAuth handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "import tweepy\n",
    "\n",
    "# Store OAuth authentication credentials in relevant variables\n",
    "access_token = \"1092294848-aHN7DcRP9B4VMTQIhwqOYiB14YkW92fFO8k8EPy\"\n",
    "access_token_secret = \"X4dHmhPfaksHcQ7SCbmZa2oYBBVSD2g8uIHXsp5CTaksx\"\n",
    "consumer_key = \"nZ6EA0FxZ293SxGNg8g8aP0HM\"\n",
    "consumer_secret = \"fJGEodwe3KiKUnsYJC3VRndj7jevVvXbK2D5EiJ2nehafRgA6i\"\n",
    "\n",
    "# Pass OAuth details to tweepy's OAuth handler\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.auth.OAuthHandler at 0x1128330f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming tweets\n",
    "\n",
    "Now that you have set up your authentication credentials, it is time to stream some tweets! We have already defined the tweet stream listener class, MyStreamListener, just as Hugo did in the introductory video. You can find the code for the tweet stream listener class here: https://gist.github.com/hugobowne/18f1c0c0709ed1a52dc5bcd462ac69f4\n",
    "\n",
    "Your task is to create the Streamobject and to filter tweets according to particular keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets.txt\", \"w\")\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write( json.dumps(tweet) + '\\n' )\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 100:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n",
      "401\n",
      "401\n",
      "401\n",
      "401\n",
      "401\n",
      "401\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4cbf42ae6ca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Filter Twitter Streams to capture data by the keywords:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clinton'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trump'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sanders'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cruz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, follow, track, is_async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filter_level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'delimited'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_async\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, is_async)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tweepy/streaming.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m                         self.retry_time = max(self.retry_420_start,\n\u001b[1;32m    260\u001b[0m                                               self.retry_time)\n\u001b[0;32m--> 261\u001b[0;31m                     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                     self.retry_time = min(self.retry_time * 2,\n\u001b[1;32m    263\u001b[0m                                           self.retry_time_cap)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize Stream listener\n",
    "l = MyStreamListener()\n",
    "\n",
    "# Create your Stream object with authentication\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(track=['clinton', 'trump', 'sanders', 'cruz'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and explore your Twitter data\n",
    "\n",
    "Now that you've got your Twitter data sitting locally in a text file, it's time to explore it! This is what you'll do in the next few interactive exercises. In this exercise, you'll read the Twitter data into a list: tweets_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['in_reply_to_user_id', 'created_at', 'filter_level', 'truncated', 'possibly_sensitive', 'timestamp_ms', 'user', 'text', 'extended_entities', 'in_reply_to_status_id', 'entities', 'favorited', 'retweeted', 'is_quote_status', 'id', 'favorite_count', 'retweeted_status', 'in_reply_to_status_id_str', 'in_reply_to_user_id_str', 'id_str', 'in_reply_to_screen_name', 'coordinates', 'lang', 'place', 'contributors', 'geo', 'retweet_count', 'source'])\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import json\n",
    "\n",
    "# String of path to file: tweets_data_path\n",
    "tweets_data_path = './data/tweets3.txt'\n",
    "\n",
    "# Initialize empty list to store tweets: tweets_data\n",
    "tweets_data = []\n",
    "\n",
    "# Open connection to file\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter data to DataFrame\n",
    "\n",
    "Now you have the Twitter data in a list of dictionaries, tweets_data, where each dictionary corresponds to a single tweet. Next, you're going to extract the text and language of each tweet. The text in a tweet, t1, is stored as the value t1['text']; similarly, the language is stored in t1['lang']. Your task is to build a DataFrame in which each row is a tweet and the columns are 'text' and 'lang'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @bpolitics: .@krollbondrating's Christopher...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @HeidiAlpine: @dmartosko Cruz video found.....</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Njihuni me Zonjën Trump !!! | Ekskluzive https...</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your an idiot she shouldn't have tried to grab...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @AlanLohner: The anti-American D.C. elites ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text lang\n",
       "0  RT @bpolitics: .@krollbondrating's Christopher...   en\n",
       "1  RT @HeidiAlpine: @dmartosko Cruz video found.....   en\n",
       "2  Njihuni me Zonjën Trump !!! | Ekskluzive https...   et\n",
       "3  Your an idiot she shouldn't have tried to grab...   en\n",
       "4  RT @AlanLohner: The anti-American D.C. elites ...   en"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns=['text', 'lang'])\n",
    "\n",
    "# Print head of DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little bit of Twitter text analysis\n",
    "\n",
    "Now that you have your DataFrame of tweets set up, you're going to do a bit of text analysis to count how many tweets contain the words 'clinton', 'trump', 'sanders' and 'cruz'. In the pre-exercise code, we have defined the following function word_in_text(), which will tell you whether the first argument (a word) occurs within the 2nd argument (a tweet).\n",
    "\n",
    "\n",
    "\n",
    "You're going to iterate over the rows of the DataFrame and calculate how many tweets contain each of our keywords! The list of objects for each candidate has been initialized to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "\n",
    "    if match:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store tweet counts\n",
    "[clinton, trump, sanders, cruz] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    clinton += word_in_text('clinton', row['text'])\n",
    "    trump += word_in_text('trump', row['text'])\n",
    "    sanders += word_in_text('sanders', row['text'])\n",
    "    cruz += word_in_text('cruz', row['text'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 77, 6, 14]\n"
     ]
    }
   ],
   "source": [
    "print([clinton, trump, sanders, cruz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting your Twitter data\n",
    "\n",
    "Now that you have the number of tweets that each candidate was mentioned in, you can plot a bar chart of this data. You'll use the statistical data visualization library seaborn, which you may not have seen before, but we'll guide you through. You'll first import seaborn as sns. You'll then construct a barplot of the data using sns.barplot, passing it two arguments:\n",
    "\n",
    "a list of labels and\n",
    "a list containing the variables you wish to plot (clinton, trump and so on.)\n",
    "Hopefully, you'll see that Trump was unreasonably represented! We have already run the previous exercise solutions in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD5CAYAAADLL+UrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a195aaa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['clinton', 'trump', 'sanders', 'cruz']\n",
    "\n",
    "# Plot histogram\n",
    "ax = sns.barplot(['clinton', 'trump', 'sanders', 'cruz'], [clinton, trump, sanders, cruz])\n",
    "ax.set(ylabel=\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Thoughts\n",
    "\n",
    "Deep dive into the Twitter API.\n",
    "Streamed\n",
    "Processed\n",
    "Visualized Results\n",
    "\n",
    "You are now able to import data from a wide array of resources.  Now adept at importing\n",
    "- Text and Flat Files\n",
    "- Local files, xls, sas, stata, pickle, html5 files\n",
    "    - make you an even better collaborator\n",
    "- sql queries\n",
    "- getting data from relational databases\n",
    "- pull data from web, and some basic html parsing\n",
    "- Pulling data from APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
